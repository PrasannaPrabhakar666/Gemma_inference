{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token can be pasted using 'Right-Click'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\PRASANNA P\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import interpreter_login\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import(\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "model_id= \"google/gemma-2b-it\"\n",
    "tokenizer= AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2b21cb459a477abdf7c0a8319ab65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a51836a52c5418e8dee871de8183bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:  55%|#####4    | 2.72G/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df5181e31e34abeada14bfa85a53125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1c50ed3903497bbbb990b77c972ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebc12112c3446ba9804829145e3fb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type='nf4'\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             quantization_config=quant_config,\n",
    "                                             device_map=\"auto\"\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prompt(prompt, your_model):\n",
    "    input_id=tokenizer(prompt,return_tensors='pt')\n",
    "    logits=your_model.generate(**input_id.to(device),\n",
    "                               max_new_tokens=500)\n",
    "    return tokenizer.decode(logits[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Madurai is the food capital of Tamil Nadu. It is known for its rich cultural heritage and traditional cuisine. The city is also a hub for various festivals and events throughout the year.\n",
      "\n",
      "**Here are some of the most popular dishes in Madurai:**\n",
      "\n",
      "* **Sadhya:** A traditional vegetarian feast that includes a variety of dishes, including rice, lentils, vegetables, and meat.\n",
      "* **Kootu Curry:** A spicy and flavorful curry made with lentils, vegetables, and meat.\n",
      "* **Pesarattu:** A traditional rice dish that is cooked in a special pot called a pesari.\n",
      "* **Kuzhambu Curry:** A creamy and flavorful curry made with vegetables and meat.\n",
      "* **Vada:** Deep-fried balls made with lentil or rice flour.\n",
      "* **Parupputtu:** A traditional rice porridge that is cooked with vegetables and meat.\n",
      "* **Pandi Curry:** A spicy and tangy curry made with lentils, vegetables, and meat.\n",
      "* **Ambur Pak:** A sweet and savory snack made with lentils, rice, and coconut.\n",
      "\n",
      "**If you are visiting Madurai, be sure to try:**\n",
      "\n",
      "* **The Sadhya** for a true taste of Tamil cuisine.\n",
      "* **The Kootu Curry** for a spicy and flavorful meal.\n",
      "* **The Pesarattu** for a unique and authentic dish.\n",
      "* **The Kuzhambu Curry** for a creamy and flavorful curry.\n",
      "* **The Vada** for a deep-fried and crispy snack.\n",
      "* **The Parupputtu** for a traditional rice porridge.\n",
      "* **The Pandi Curry** for a spicy and tangy dish.\n",
      "* **The Ambur Pak** for a sweet and savory snack.\n",
      "\n",
      "**Tips for eating out in Madurai:**\n",
      "\n",
      "* **Dress conservatively** when eating out, as Madurai is a conservative city.\n",
      "* **Avoid eating in crowded areas** and stick to more popular restaurants.\n",
      "* **Negotiate the price** before you order, as prices can be high in Madurai.\n",
      "* **Try the local street food** for a authentic experience.\n",
      "* **Be patient** when waiting for your food, as Madurai is known for its slow cooking methods.<eos>\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Madurai is the food capital\"\n",
    "output=test_prompt(test_text,model)\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
